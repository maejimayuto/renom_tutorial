{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuto.maejima/work/projects/renom_tutorial/ReNom/renom/cuda/__init__.py:28: UserWarning: Couldn't find cuda modules.\n",
      "  warnings.warn(\"Couldn't find cuda modules.\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from xml.etree import ElementTree\n",
    "from itertools import product\n",
    "import urllib.request as request\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "import colorsys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ReNom version >= 2.3.0\n",
    "import renom as rm\n",
    "from renom.cuda import set_cuda_active\n",
    "from renom.utility.trainer import Trainer\n",
    "from renom.algorithm.image.detection.yolo import build_truth, Yolo, apply_nms, box_iou\n",
    "from renom.utility.distributor import ImageDetectionDistributor\n",
    "from renom.utility.image import *\n",
    "\n",
    "set_cuda_active(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'VOCdevkit/VOC2012/Annotations/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6124943357f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"VOCdevkit/VOC2012/Annotations/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_file_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m\"2012_\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_file_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"2012_\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'VOCdevkit/VOC2012/Annotations/'"
     ]
    }
   ],
   "source": [
    "dataset_path = \"VOCdevkit/VOC2012/Annotations/\"\n",
    "\n",
    "train_file_list = [path for path in sorted(os.listdir(dataset_path)) if not \"2012_\" in path]\n",
    "test_file_list = [path for path in os.listdir(dataset_path) if \"2012_\" in path]\n",
    "\n",
    "tree = ElementTree.parse(os.path.join(dataset_path, train_file_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(node, indent=1):\n",
    "    print(\"{}{} {}\".format('    ' * indent, node.tag, node.text.strip()))\n",
    "    for child in node:\n",
    "        parse(child, indent + 1)\n",
    "\n",
    "print(\"/// Contents of a XML file ///\")\n",
    "parse(tree.getroot())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {}\n",
    "img_size = (224*2, 224*2)\n",
    "cells = 7\n",
    "\n",
    "def get_obj_coordinate(obj):\n",
    "    global label_dict\n",
    "    class_name = obj.find(\"name\").text.strip()\n",
    "    if label_dict.get(class_name, None) is None:\n",
    "        label_dict[class_name] = len(label_dict)\n",
    "    class_id = label_dict[class_name]\n",
    "    bbox = obj.find(\"bndbox\")\n",
    "    xmax = float(bbox.find(\"xmax\").text.strip())\n",
    "    xmin = float(bbox.find(\"xmin\").text.strip())\n",
    "    ymax = float(bbox.find(\"ymax\").text.strip())\n",
    "    ymin = float(bbox.find(\"ymin\").text.strip())\n",
    "    w = xmax - xmin\n",
    "    h = ymax - ymin\n",
    "    x = xmin + w/2\n",
    "    y = ymin + h/2\n",
    "    return class_id, x, y, w, h\n",
    "\n",
    "def get_img_info(filename):\n",
    "    tree = ElementTree.parse(filename)\n",
    "    node = tree.getroot()\n",
    "    file_name = node.find(\"filename\").text.strip()\n",
    "    img_h = float(node.find(\"size\").find(\"height\").text.strip())\n",
    "    img_w = float(node.find(\"size\").find(\"width\").text.strip())\n",
    "    obj_list = node.findall(\"object\")\n",
    "    objects = []\n",
    "    for obj in obj_list:\n",
    "        objects.append(get_obj_coordinate(obj))\n",
    "    return file_name, img_w, img_h, objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_set = []\n",
    "test_data_set = []\n",
    "\n",
    "for o in train_file_list:\n",
    "    train_data_set.append(get_img_info(os.path.join(dataset_path, o)))\n",
    "\n",
    "for o in test_file_list:\n",
    "    test_data_set.append(get_img_info(os.path.join(dataset_path, o)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example and class labels.\n",
    "print(\"{}\".format(train_data_set[-1]))\n",
    "print()\n",
    "print(\"%-12s: number\"%(\"class name\"))\n",
    "print(\"----------------------\")\n",
    "for k, v in sorted(label_dict.items(), key=lambda x:x[1]):\n",
    "    print(\"%-12s: %d\"%(k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_length = len(label_dict)\n",
    "last_layer_size = cells*cells*(5*2+label_length)\n",
    "\n",
    "def one_hot(label):\n",
    "    oh = [0]*label_length\n",
    "    oh[label] = 1\n",
    "    return oh\n",
    "\n",
    "def create_detection_distributor(train_set=True):\n",
    "    label_data = []\n",
    "    img_path_list = []\n",
    "    label_list = []\n",
    "    if train_set:\n",
    "        file_list = train_file_list\n",
    "        data_set = train_data_set\n",
    "        # Augumentation Settngs\n",
    "        augmentatiion = DataAugmentation(\n",
    "            [\n",
    "                Flip(1),\n",
    "                Rotate(90),\n",
    "                # Resize(size=img_size),\n",
    "                Shift((20, 20)),\n",
    "                # ColorJitter(v=(1.0, 1.5)),\n",
    "                # Zoom(zoom_rate=(1.0, 1.1)),\n",
    "                Rescale(option=[-1, 1])\n",
    "            ],\n",
    "            random=True\n",
    "        )\n",
    "    else:\n",
    "        file_list = test_file_list\n",
    "        data_set = test_data_set\n",
    "        augmentatiion = DataAugmentation(\n",
    "            [Rescale(option=[-1, 1])],\n",
    "        )\n",
    "    for i in range(len(file_list)):\n",
    "        img_path = os.path.join(\"VOCdevkit/VOC2012/JPEGImages/\", data_set[i][0])\n",
    "\n",
    "        # obj[1]:X, obj[2]:Y, obj[3]:Width, obj[4]:Height, obj[0]:Class\n",
    "        objects = []\n",
    "        for obj in data_set[i][3]:\n",
    "            detect_label = {\"bndbox\":[obj[1], obj[2], obj[3], obj[4]],\n",
    "                            \"name\":one_hot(obj[0])}\n",
    "            objects.append(detect_label)\n",
    "        img_path_list.append(img_path)\n",
    "        label_list.append(objects)\n",
    "    class_list = [c for c, v in sorted(label_dict.items(), key=lambda x:x[1])]\n",
    "    return ImageDetectionDistributor(img_path_list,\n",
    "                                     label_list,\n",
    "                                     class_list,\n",
    "                                     imsize = img_size,\n",
    "                                     augmentation=augmentatiion)\n",
    "\n",
    "def transform_to_yolo_format(label):\n",
    "    yolo_format = []\n",
    "    for l in label:\n",
    "        yolo_format.append(build_truth(l.reshape(1, -1), img_size[0], img_size[1], cells, label_length).flatten())\n",
    "    return np.array(yolo_format)\n",
    "\n",
    "def draw_rect(draw_obj, rect):\n",
    "    cor = (rect[0][0], rect[0][1], rect[1][0], rect[1][1])\n",
    "    line_width = 3\n",
    "    for i in range(line_width):\n",
    "        draw_obj.rectangle(cor, outline=\"red\")\n",
    "        cor = (cor[0]+1,cor[1]+1, cor[2]+1,cor[3]+1)\n",
    "\n",
    "train_detect_dist = create_detection_distributor(True)\n",
    "test_detect_dist = create_detection_distributor(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample, sample_label = train_detect_dist.batch(3, shuffle=True).__next__()\n",
    "\n",
    "for Mth_img in range(len(sample)):\n",
    "    example_img = Image.fromarray(((sample[Mth_img]+1)*255/2).transpose(1, 2, 0).astype(np.uint8))\n",
    "    dr = ImageDraw.Draw(example_img)\n",
    "\n",
    "    print(\"///Objects\")\n",
    "    for i in range(0, len(sample_label[Mth_img]), 4+label_length):\n",
    "        class_label = np.argmax(sample_label[Mth_img][i+4:i+4+label_length])\n",
    "        x, y, w, h = sample_label[Mth_img][i:i+4]\n",
    "        if x==y==h==w==0:\n",
    "            break\n",
    "        draw_rect(dr, ((x-w/2, y-h/2), (x+w/2, y+h/2)))\n",
    "        print(\"obj:%d\"%(i+1),\n",
    "              \"class:{:7s}\".format([k for k, v in label_dict.items() if v==class_label][0]),\n",
    "              \"x:%3d, y:%3d width:%3d height:%3d\"%(x, y, w, h))\n",
    "\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.imshow(example_img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional neural network\n",
    "model = rm.Sequential([\n",
    "    # 1st Block\n",
    "    rm.Conv2d(channel=64, filter=7, stride=2, padding=3),\n",
    "    rm.LeakyRelu(slope=0.1),\n",
    "    rm.MaxPool2d(stride=2, filter=2),\n",
    "\n",
    "    # 2nd Block\n",
    "    rm.Conv2d(channel=192, filter=3, padding=1),\n",
    "    rm.LeakyRelu(slope=0.1),\n",
    "    rm.MaxPool2d(stride=2, filter=2),\n",
    "\n",
    "    # 3rd Block\n",
    "    rm.Conv2d(channel=128, filter=1),\n",
    "    rm.LeakyRelu(slope=0.1),\n",
    "    rm.Conv2d(channel=256, filter=3, padding=1),\n",
    "    rm.LeakyRelu(slope=0.1),\n",
    "    rm.Conv2d(channel=256, filter=1),\n",
    "    rm.LeakyRelu(slope=0.1),\n",
    "    rm.Conv2d(channel=512, filter=3, padding=1),\n",
    "    rm.LeakyRelu(slope=0.1),\n",
    "    rm.MaxPool2d(stride=2, filter=2),\n",
    "\n",
    "    # 4th Block\n",
    "    rm.Conv2d(channel=256, filter=1),\n",
    "    rm.LeakyRelu(slope=0.1),\n",
    "    rm.Conv2d(channel=512, filter=3, padding=1),\n",
    "    rm.LeakyRelu(slope=0.1),\n",
    "    rm.Conv2d(channel=256, filter=1),\n",
    "    rm.LeakyRelu(slope=0.1),\n",
    "    rm.Conv2d(channel=512, filter=3, padding=1),\n",
    "    rm.LeakyRelu(slope=0.1),\n",
    "    rm.Conv2d(channel=256, filter=1),\n",
    "    rm.LeakyRelu(slope=0.1),\n",
    "    rm.Conv2d(channel=512, filter=3, padding=1),\n",
    "    rm.LeakyRelu(slope=0.1),\n",
    "    rm.Conv2d(channel=256, filter=1),\n",
    "    rm.LeakyRelu(slope=0.1),\n",
    "    rm.Conv2d(channel=512, filter=3, padding=1),\n",
    "    rm.LeakyRelu(slope=0.1),\n",
    "    rm.Conv2d(channel=512, filter=1),\n",
    "    rm.LeakyRelu(slope=0.1),\n",
    "    rm.Conv2d(channel=1024, filter=3, padding=1),\n",
    "    rm.LeakyRelu(slope=0.1),\n",
    "    rm.MaxPool2d(stride=2, filter=2),\n",
    "\n",
    "    # 5th Block\n",
    "    rm.Conv2d(channel=512, filter=1),\n",
    "    rm.LeakyRelu(slope=0.1),\n",
    "    rm.Conv2d(channel=1024, filter=3, padding=1),\n",
    "    rm.LeakyRelu(slope=0.1),\n",
    "    rm.Conv2d(channel=512, filter=1),\n",
    "    rm.LeakyRelu(slope=0.1),\n",
    "    rm.Conv2d(channel=1024, filter=3, padding=1),\n",
    "    rm.LeakyRelu(slope=0.1),\n",
    "    rm.Conv2d(channel=1024, filter=3, padding=1),\n",
    "    rm.LeakyRelu(slope=0.1),\n",
    "    rm.Conv2d(channel=1024, filter=3, stride=2, padding=1),\n",
    "    rm.LeakyRelu(slope=0.1),\n",
    "\n",
    "    # 6th Block\n",
    "    rm.Conv2d(channel=1024, filter=3, padding=1),\n",
    "    rm.LeakyRelu(slope=0.1),\n",
    "    rm.Conv2d(channel=1024, filter=3, padding=1),\n",
    "    rm.LeakyRelu(slope=0.1),\n",
    "\n",
    "    # 7th Block\n",
    "    rm.Flatten(),\n",
    "    rm.Dense(512),\n",
    "    rm.LeakyRelu(slope=0.1),\n",
    "    rm.Dense(4096),\n",
    "    rm.LeakyRelu(slope=0.1),\n",
    "    rm.Dropout(0.5),\n",
    "\n",
    "    # 8th Block\n",
    "    rm.Dense(last_layer_size),\n",
    "])\n",
    "\n",
    "# Loss function.\n",
    "yolo_detector = Yolo(cells=cells, classes=label_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(train_data_set)\n",
    "batch = 64\n",
    "batch_loop = int(np.ceil(N/batch))\n",
    "\n",
    "# Download the learned model weights.\n",
    "if not os.path.exists(\"yolo.h5\"):\n",
    "    print(\"Weight parameters will be downloaded.\")\n",
    "    url = \"http://docs.renom.jp/downloads/weights/yolo.h5\"\n",
    "    request.urlretrieve(url, \"yolo.h5\")\n",
    "\n",
    "model.load(\"yolo.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_upper = rm.Sequential(model[:-7])\n",
    "model_detector = rm.Sequential(model[-7:])\n",
    "\n",
    "# Define weight decay\n",
    "def weight_decay():\n",
    "    wd = 0\n",
    "    for m in model_detector:\n",
    "        if hasattr(m, \"params\"):\n",
    "            w = m.params.get(\"w\", None)\n",
    "            if w is not None:\n",
    "                wd += rm.sum(w**2)\n",
    "    return wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset params of detector model for redoing the learning.\n",
    "LEARN = False # True if relearning the model.\n",
    "if LEARN:\n",
    "    for layer in model_detector:\n",
    "        if hasattr(layer, \"params\"):\n",
    "            layer.params = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = rm.Sgd(momentum=0.9)\n",
    "\n",
    "# We use different learning rate in each epoch.\n",
    "lrarning_rates = []# [0.001] + [0.01]*60\n",
    "\n",
    "for epoch in range(len(lrarning_rates) * LEARN):\n",
    "    loss = 0\n",
    "    test_loss = 0\n",
    "    bar = tqdm(range(batch_loop))\n",
    "    opt._lr = lrarning_rates[epoch]\n",
    "\n",
    "    model_detector.set_models(inference=False)\n",
    "    for j, (img, label) in enumerate(train_detect_dist.batch(batch, True)):\n",
    "        if epoch==0:\n",
    "            # Rise the learning rate slowly at first epoch.\n",
    "            opt._lr = (0.01 - 0.001)/(batch_loop)*j + 0.001\n",
    "\n",
    "        yolo_format_label = transform_to_yolo_format(label)\n",
    "        h = model_upper(img).as_ndarray()\n",
    "\n",
    "        with model_detector.train():\n",
    "            z = model_detector(h)\n",
    "            l = yolo_detector(z, yolo_format_label) + 0.0005*weight_decay()\n",
    "\n",
    "        l.grad().update(opt)\n",
    "        loss += l.as_ndarray()\n",
    "\n",
    "        # Set descriptions to tqdm.\n",
    "        bar.set_description(\"epoch {:03d} train loss:{:6.4f}\".format(epoch, l.as_ndarray()[0]))\n",
    "        bar.update(1)\n",
    "\n",
    "    # Test\n",
    "    model_detector.set_models(inference=True)\n",
    "    for k, (img, label) in enumerate(test_detect_dist.batch(batch, True)):\n",
    "        yolo_format_label = transform_to_yolo_format(label)\n",
    "        h = model_upper(img).as_ndarray()\n",
    "        z = model_detector(h)\n",
    "        test_loss += yolo_detector(z, yolo_format_label) + 0.0005*weight_decay()\n",
    "    test_loss = test_loss.as_ndarray()/(k+1)\n",
    "\n",
    "    msg = \"epoch {:03d} avg loss:{:6.4f} test loss:{:6.4f}\".format(epoch, float(loss/(j+1)), float(test_loss))\n",
    "    bar.set_description(msg)\n",
    "    bar.update(0)\n",
    "    bar.refresh()\n",
    "    bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img, sample_label = test_detect_dist.batch(3, shuffle=True).__next__()\n",
    "obj_list = []\n",
    "\n",
    "model.set_models(inference=True)\n",
    "for i in range(len(sample_img)):\n",
    "    p = model(np.expand_dims(sample_img[i], axis=0)).as_ndarray().reshape(cells, cells, 5*2+label_length)\n",
    "    objs = apply_nms(p, cells, 2, label_length, image_size=img_size, thresh=0.2)\n",
    "    obj_list.append(objs)\n",
    "\n",
    "for num in range(3):\n",
    "    im = Image.fromarray(((sample_img[num] + 1)/2*255).transpose(1, 2, 0).astype(np.uint8))\n",
    "    obj = obj_list[num]\n",
    "    dr = ImageDraw.Draw(im)\n",
    "    print(\"///Objects\")\n",
    "    for i in range(len(obj)):\n",
    "        class_label = obj[i][\"class\"]\n",
    "        w = obj[i][\"box\"][2]*448\n",
    "        h = obj[i][\"box\"][3]*448\n",
    "        x = obj[i][\"box\"][0]*448\n",
    "        y = obj[i][\"box\"][1]*448\n",
    "        x1 = x - w/2\n",
    "        y1 = y - h/2\n",
    "        x2 = x + w/2\n",
    "        y2 = y + h/2\n",
    "        print(\"obj:%d\"%(i+1),\n",
    "          \"class:{:7s}\".format([k for k, v in label_dict.items() if v==class_label][0]),\n",
    "          \"x:%3d, y:%3d width:%3d height:%3d\"%(x, y, w, h))\n",
    "        draw_rect(dr, ((x1, y1), (x2, y2)))\n",
    "    plt.imshow(im)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
