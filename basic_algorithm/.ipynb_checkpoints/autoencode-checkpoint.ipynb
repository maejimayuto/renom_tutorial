{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.seterr(all=\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import renom as rm\n",
    "from renom.optimizer import Adam\n",
    "from renom.utility.initializer import Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'data_path' must point to the directory containing the data folder.\n",
    "data_path = \"../dataset\"\n",
    "mnist = fetch_mldata('MNIST original', data_home=data_path)\n",
    "\n",
    "X = mnist.data\n",
    "y = mnist.target\n",
    "\n",
    "# Binarize (\"one-hot\") the image data.\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.float32)\n",
    "X = np.array(X > 128, dtype=np.float32)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "binarizer = LabelBinarizer()\n",
    "label_train = binarizer.fit_transform(y_train)\n",
    "label_test = binarizer.transform(y_test)\n",
    "\n",
    "# Training data size.\n",
    "N = len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ae = rm.Sequential([\n",
    "        rm.Dense(100),\n",
    "        rm.Relu(),\n",
    "        rm.Dense(784),\n",
    "    ])\n",
    "optimizer = Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 64\n",
    "epoch = 10\n",
    "\n",
    "for i in range(epoch):\n",
    "    for j in range(N//batch):\n",
    "        train_batch=x_train[j*batch:(j+1)*batch]\n",
    "        with model_ae.train():\n",
    "            z = model_ae(train_batch)\n",
    "            loss = rm.sigmoid_cross_entropy(z, train_batch)\n",
    "        loss.grad().update(optimizer)\n",
    "    if i%2 == 0:print(\"epoch %02d train_loss:%f\"%(i, loss))\n",
    "\n",
    "# Show raw img and reconstructed img.\n",
    "test_img = x_test[0]\n",
    "fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(8, 6))\n",
    "ax[0].set_title(\"Raw image\")\n",
    "ax[0].imshow(test_img.reshape(28, 28), cmap=\"gray\")\n",
    "ax[1].set_title(\"Reconstructed image\")\n",
    "ax[1].imshow(rm.sigmoid(model_ae(test_img)).reshape(28, 28), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = x_test[0].reshape(28, 28)\n",
    "sp_noise = np.array(np.random.rand(*test_img.shape) > 0.5, dtype=np.bool)\n",
    "fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(8, 6))\n",
    "ax[0].set_title(\"Raw image\")\n",
    "ax[0].imshow(test_img, cmap=\"gray\")\n",
    "ax[1].set_title(\"Added salt and pepper noise\")\n",
    "ax[1].imshow(test_img*sp_noise, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_denoise_ae = rm.Sequential([\n",
    "        rm.Dense(100),\n",
    "        rm.Relu(),\n",
    "        rm.Dense(784),\n",
    "    ])\n",
    "optimizer = Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 64\n",
    "epoch = 10\n",
    "\n",
    "for i in range(epoch):\n",
    "    for j in range(N//batch):\n",
    "        train_batch=x_train[j*batch:(j+1)*batch]\n",
    "        with model_denoise_ae.train():\n",
    "            sp_noise = np.array(np.random.rand(*train_batch.shape) > 0.5, dtype=np.bool)\n",
    "            z = model_denoise_ae(train_batch*sp_noise)\n",
    "            loss = rm.sigmoid_cross_entropy(z, train_batch)\n",
    "        loss.grad().update(optimizer)\n",
    "    if i%2 == 0:print(\"epoch %02d train_loss:%f\"%(i, loss))\n",
    "\n",
    "# Show raw img and reconstructed img.\n",
    "test_img = x_test[0]\n",
    "fig, ax = plt.subplots(ncols=2, nrows=1, figsize=(8, 6))\n",
    "ax[0].set_title(\"Raw image\")\n",
    "ax[0].imshow(test_img.reshape(28, 28), cmap=\"gray\")\n",
    "ax[1].set_title(\"Reconstructed image\")\n",
    "ax[1].imshow(rm.sigmoid(model_denoise_ae(test_img)).reshape(28, 28), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_ae = rm.Sequential([\n",
    "        rm.Dense(100),\n",
    "        rm.Relu(),\n",
    "        rm.Dense(10),\n",
    "    ])\n",
    "\n",
    "pretrained_dae = rm.Sequential([\n",
    "        rm.Dense(100),\n",
    "        rm.Relu(),\n",
    "        rm.Dense(10),\n",
    "    ])\n",
    "\n",
    "# Copy first weight parameters of first layer.\n",
    "pretrained_ae[0].params = model_ae[0].params\n",
    "pretrained_dae[0].params = model_denoise_ae[0].params\n",
    "\n",
    "opt1 = Adam()\n",
    "opt2 = Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 64\n",
    "epoch = 40\n",
    "\n",
    "train_loss1 = []\n",
    "train_loss2 = []\n",
    "validation_loss1 = []\n",
    "validation_loss2 = []\n",
    "\n",
    "for i in range(epoch):\n",
    "    for j in range(N//batch):\n",
    "        train_batch = x_train[j*batch:(j+1)*batch]\n",
    "        response_batch = label_train[j*batch:(j+1)*batch].astype(np.float32)\n",
    "        sp_noise = np.array(np.random.rand(*train_batch.shape) > 0.5)\n",
    "        train_batch = train_batch*sp_noise\n",
    "\n",
    "        with pretrained_ae.train():\n",
    "            z = pretrained_ae(train_batch)\n",
    "            loss1 = rm.softmax_cross_entropy(z, response_batch)\n",
    "\n",
    "        with pretrained_dae.train():\n",
    "            z = pretrained_dae(train_batch)\n",
    "            loss2 = rm.softmax_cross_entropy(z, response_batch)\n",
    "\n",
    "        loss1.grad().update(opt1)\n",
    "        loss2.grad().update(opt2)\n",
    "\n",
    "    validation1 = rm.softmax_cross_entropy(pretrained_ae(x_test), label_test)\n",
    "    validation2 = rm.softmax_cross_entropy(pretrained_dae(x_test), label_test)\n",
    "\n",
    "    train_loss1.append(loss1)\n",
    "    train_loss2.append(loss2)\n",
    "    validation_loss1.append(validation1)\n",
    "    validation_loss2.append(validation2)\n",
    "\n",
    "    strs = \"epoch:%02d AE_loss:%f AE_validation:%f DAE_loss:%f DAE_validation:%f\"\n",
    "    if i%2 == 0:print(strs%(i, loss1, validation1, loss2, validation2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.grid()\n",
    "plt.plot(train_loss1, label=\"AE_train_loss\", linestyle=\"--\", linewidth=3)\n",
    "plt.plot(validation_loss1, label=\"AE_validation_loss\", linewidth=3)\n",
    "plt.plot(train_loss2, label=\"DAE_train_loss\", linestyle=\"--\", linewidth=3)\n",
    "plt.plot(validation_loss2, label=\"DAE_validation_loss\", linewidth=3)\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction1 = np.argmax(pretrained_ae(x_test).as_ndarray(), axis = 1)\n",
    "prediction2 = np.argmax(pretrained_dae(x_test).as_ndarray(), axis = 1)\n",
    "\n",
    "print(\"///////////// AE pretrained model //////////////\")\n",
    "print(classification_report(np.argmax(label_test, axis = 1), prediction1))\n",
    "\n",
    "print(\"///////////// DAE pretrained model //////////////\")\n",
    "print(classification_report(np.argmax(label_test, axis = 1), prediction2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
