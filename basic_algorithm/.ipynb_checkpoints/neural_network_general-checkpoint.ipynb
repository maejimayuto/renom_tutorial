{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import renom as rm\n",
    "from renom.optimizer import Sgd, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0  batch:0 weight shape:(4, 10) bias shape:(1, 10)\n",
      "weight:[[ 0.64742726  0.27625507  0.17133488  0.19763127  0.55397773 -0.47762734\n",
      "  -0.57897902  0.31392923  0.27851468  0.60068846]\n",
      " [ 0.38203418  0.35468498 -0.23334123 -0.2322093   0.57833642 -1.17980492\n",
      "   0.31800449 -0.56395161  0.19159485  0.28666806]\n",
      " [-0.00172069  0.1375021  -0.91491485 -0.95289683 -0.43993112  0.37406582\n",
      "   1.11680853 -0.36054561 -0.09321212 -0.28480694]\n",
      " [ 0.16812949 -0.05025169  0.51161891 -0.32363158  0.25285947 -0.61811912\n",
      "   0.14737503  0.47638699  0.37341103  0.59701198]]\n",
      "bias:[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "epoch:0  batch:1 weight shape:(4, 10) bias shape:(1, 10)\n",
      "weight:[[ 0.64601004  0.27459842  0.17133488  0.19763127  0.55288261 -0.47762734\n",
      "  -0.57674879  0.31392923  0.27571294  0.60178971]\n",
      " [ 0.38151702  0.35341021 -0.23334123 -0.2322093   0.57765943 -1.17980492\n",
      "   0.3190614  -0.56395161  0.19027802  0.28715935]\n",
      " [-0.00321594  0.13726649 -0.91491485 -0.95289683 -0.44046068  0.37406582\n",
      "   1.11860991 -0.36054561 -0.09550384 -0.28384674]\n",
      " [ 0.16755858 -0.05022275  0.51161891 -0.32363158  0.2527065  -0.61811912\n",
      "   0.14801742  0.47638699  0.37258822  0.59736276]]\n",
      "bias:[[-0.00019676 -0.00034006  0.          0.         -0.00019758  0.\n",
      "   0.00035023  0.         -0.00043736  0.00016759]]\n",
      "\n",
      "epoch:0  batch:2 weight shape:(4, 10) bias shape:(1, 10)\n",
      "weight:[[ 0.6433171   0.27329016  0.17133488  0.19763127  0.55156845 -0.47762734\n",
      "  -0.57299411  0.31392923  0.27108279  0.60376954]\n",
      " [ 0.3804183   0.3523742  -0.23334123 -0.2322093   0.5769158  -1.17980492\n",
      "   0.32078549 -0.56395161  0.1881631   0.28803995]\n",
      " [-0.00568989  0.13710599 -0.91491485 -0.95289683 -0.44123778  0.37406582\n",
      "   1.12166345 -0.36054561 -0.09928871 -0.28217998]\n",
      " [ 0.1666728  -0.05019021  0.51161891 -0.32363158  0.25246543 -0.61811912\n",
      "   0.14907517  0.47638699  0.37127393  0.59794599]]\n",
      "bias:[[-0.0005879  -0.00062515  0.          0.         -0.00042772  0.\n",
      "   0.0009325   0.         -0.00115268  0.00046899]]\n",
      "\n",
      "epoch:1  batch:0 weight shape:(4, 10) bias shape:(1, 10)\n",
      "weight:[[ 0.62712514  0.2598232   0.17133488  0.19763127  0.54203731 -0.47762734\n",
      "  -0.52463329  0.31392923  0.22593406  0.6338706 ]\n",
      " [ 0.37519091  0.33921215 -0.23334123 -0.2322093   0.57030773 -1.17980492\n",
      "   0.34291562 -0.56395161  0.16772074  0.30129188]\n",
      " [-0.02355984  0.14328834 -0.91491485 -0.95289683 -0.44330782  0.37406582\n",
      "   1.16016304 -0.36054561 -0.13554092 -0.25689653]\n",
      " [ 0.15988745 -0.0460381   0.51161891 -0.32363158  0.25240698 -0.61811912\n",
      "   0.1625167   0.47638699  0.35860446  0.60694414]]\n",
      "bias:[[-0.00274509 -0.00406028  0.          0.         -0.0023547   0.\n",
      "   0.00860909  0.         -0.00827151  0.00515173]]\n",
      "\n",
      "epoch:1  batch:1 weight shape:(4, 10) bias shape:(1, 10)\n",
      "weight:[[ 0.62652373  0.26002419  0.17133488  0.19763127  0.54205704 -0.47762734\n",
      "  -0.5197075   0.31392923  0.22248934  0.63738012]\n",
      " [ 0.37508389  0.33868992 -0.23334123 -0.2322093   0.57011515 -1.17980492\n",
      "   0.34521928 -0.56395161  0.1661211   0.30287981]\n",
      " [-0.02450126  0.14501716 -0.91491485 -0.95289683 -0.44277999  0.37406582\n",
      "   1.16425097 -0.36054561 -0.13842957 -0.25384876]\n",
      " [ 0.15949026 -0.04520629  0.51161891 -0.32363158  0.25266582 -0.61811912\n",
      "   0.16398458  0.47638699  0.35756353  0.60805696]]\n",
      "bias:[[-0.0028035  -0.00415845  0.          0.         -0.00239422  0.\n",
      "   0.00938563  0.         -0.00881232  0.00569368]]\n",
      "\n",
      "epoch:1  batch:2 weight shape:(4, 10) bias shape:(1, 10)\n",
      "weight:[[ 0.62593728  0.26090935  0.17133488  0.19763127  0.54236746 -0.47762734\n",
      "  -0.51456785  0.31392923  0.21907669  0.64114428]\n",
      " [ 0.37494856  0.33860758 -0.23334123 -0.2322093   0.57009792 -1.17980492\n",
      "   0.34762996 -0.56395161  0.16452831  0.30460247]\n",
      " [-0.02534646  0.14704937 -0.91491485 -0.95289683 -0.44209793  0.37406582\n",
      "   1.16839755 -0.36054561 -0.14120832 -0.2506983 ]\n",
      " [ 0.15913852 -0.0442997   0.51161891 -0.32363158  0.25296873 -0.61811912\n",
      "   0.16545175  0.47638699  0.35657647  0.6091879 ]]\n",
      "bias:[[-0.00287847 -0.00408671  0.          0.         -0.00236714  0.\n",
      "   0.01023315  0.         -0.00937291  0.00630812]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Model(rm.Model):\n",
    "    def __init__(self):\n",
    "        self.layer1 = rm.Dense(10)\n",
    "        self.layer2 = rm.Dense(3)\n",
    "    def forward(self, x, epoch, batch):\n",
    "        t1 = rm.relu(self.layer1(x))\n",
    "        out = self.layer2(t1)\n",
    "        if epoch is not None and epoch < 2 and batch < 3:\n",
    "            print(\"epoch:{}  batch:{} weight shape:{} bias shape:{}\".format(epoch, batch, self.layer1.params.w.shape, self.layer1.params.b.shape))\n",
    "            print(\"weight:{}\".format(self.layer1.params.w))\n",
    "            print(\"bias:{}\".format(self.layer1.params.b))\n",
    "            print()\n",
    "        return out\n",
    "\n",
    "iris = load_iris()\n",
    "data = iris.data\n",
    "label = iris.target\n",
    "\n",
    "model = Model()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.3)\n",
    "y_train = y_train.reshape(len(X_train), -1)\n",
    "y_test = y_test.reshape(len(X_test), -1)\n",
    "batch_size = 8\n",
    "epoch = 10\n",
    "N = len(X_train)\n",
    "optimizer = Sgd(lr=0.001)\n",
    "\n",
    "for i in range(epoch):\n",
    "    perm = np.random.permutation(N)\n",
    "    loss = 0\n",
    "    for j in range(0, N // batch_size):\n",
    "        train_batch = X_train[perm[j*batch_size : (j+1)*batch_size]]\n",
    "        response_batch = y_train[perm[j*batch_size : (j+1)*batch_size]]\n",
    "\n",
    "        with model.train():\n",
    "            l = rm.softmax_cross_entropy(model(train_batch, i, j), response_batch)\n",
    "        grad = l.grad()\n",
    "        grad.update(optimizer)\n",
    "        loss += l.as_ndarray()\n",
    "    train_loss = loss / (N // batch_size)\n",
    "\n",
    "    test_loss = rm.softmax_cross_entropy(model(X_test, None, None), y_test).as_ndarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "X, y = make_regression(n_samples=500, n_features=1, random_state=0, noise=4.0, bias=100.0)\n",
    "X = - X\n",
    "plt.scatter(X, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:000, train_loss:9711.5872, test_loss:7933.6201\n",
      "epoch:001, train_loss:3268.0862, test_loss:1949.3250\n",
      "epoch:002, train_loss:1592.0592, test_loss:1257.3204\n",
      "epoch:003, train_loss:1270.5661, test_loss:1123.8812\n",
      "epoch:004, train_loss:1172.8830, test_loss:1077.5361\n",
      "epoch:005, train_loss:981.2783, test_loss:763.8190\n",
      "epoch:006, train_loss:718.0260, test_loss:713.4895\n",
      "epoch:007, train_loss:678.3314, test_loss:739.8529\n",
      "epoch:008, train_loss:682.9186, test_loss:675.0548\n",
      "epoch:009, train_loss:655.9001, test_loss:740.3343\n"
     ]
    }
   ],
   "source": [
    "class Model(rm.Model):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.w1 = rm.Variable(np.random.randn(input_size, hidden_size)*0.01)\n",
    "        self.w2 = rm.Variable(np.random.randn(hidden_size, output_size)*0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        t1 = rm.dot(x, self.w1)\n",
    "        t2 = rm.relu(t1)\n",
    "        out = rm.dot(t2, self.w2)\n",
    "        return out\n",
    "\n",
    "data, label = make_regression(n_samples=500, n_features=5, random_state=0, noise=4.0, bias=100.0)\n",
    "data = - data\n",
    "\n",
    "model = Model(input_size=data.shape[1], hidden_size=10, output_size=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.3)\n",
    "y_train = y_train.reshape(len(X_train), -1)\n",
    "y_test = y_test.reshape(len(X_test), -1)\n",
    "batch_size = 8\n",
    "epoch = 10\n",
    "N = len(X_train)\n",
    "optimizer = Sgd(lr=0.001)\n",
    "\n",
    "for i in range(epoch):\n",
    "    perm = np.random.permutation(N)\n",
    "    loss = 0\n",
    "    for j in range(0, N // batch_size):\n",
    "        train_batch = X_train[perm[j*batch_size : (j+1)*batch_size]]\n",
    "        response_batch = y_train[perm[j*batch_size : (j+1)*batch_size]]\n",
    "\n",
    "        with model.train():\n",
    "            l = rm.mean_squared_error(model(train_batch), response_batch)\n",
    "        grad = l.grad()\n",
    "        grad.update(optimizer)\n",
    "        loss += l.as_ndarray()\n",
    "    train_loss = loss / (N // batch_size)\n",
    "\n",
    "    test_loss = rm.mean_squared_error(model(X_test), y_test).as_ndarray()\n",
    "    print(\"epoch:{:03d}, train_loss:{:.4f}, test_loss:{:.4f}\".format(i, float(train_loss), float(test_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:000, train_loss:7412.8418, test_loss:450.6481\n",
      "epoch:001, train_loss:583.1694, test_loss:312.8645\n",
      "epoch:002, train_loss:564.7602, test_loss:304.0845\n",
      "epoch:003, train_loss:530.9770, test_loss:247.5939\n",
      "epoch:004, train_loss:318.2821, test_loss:85.9422\n",
      "epoch:005, train_loss:119.9338, test_loss:88.8588\n",
      "epoch:006, train_loss:92.7430, test_loss:78.3222\n",
      "epoch:007, train_loss:86.0095, test_loss:69.7287\n",
      "epoch:008, train_loss:71.5348, test_loss:62.0348\n",
      "epoch:009, train_loss:57.0815, test_loss:45.4668\n"
     ]
    }
   ],
   "source": [
    "class Model(rm.Model):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.w1 = rm.Variable(np.random.randn(input_size, hidden_size)*0.01)\n",
    "        self.b1 = rm.Variable(np.zeros((1, hidden_size)))\n",
    "        self.w2 = rm.Variable(np.random.randn(hidden_size, output_size)*0.01)\n",
    "        self.b2 = rm.Variable(np.zeros((1, output_size)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        t1 = rm.dot(x, self.w1) + self.b1\n",
    "        t2 = rm.relu(t1)\n",
    "        out = rm.dot(t2, self.w2) + self.b2\n",
    "        return out\n",
    "\n",
    "data, label = make_regression(n_samples=500, n_features=5, random_state=0, noise=4.0, bias=100.0)\n",
    "data = - data\n",
    "\n",
    "model = Model(input_size=data.shape[1], hidden_size=10, output_size=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.3)\n",
    "y_train = y_train.reshape(len(X_train), -1)\n",
    "y_test = y_test.reshape(len(X_test), -1)\n",
    "batch_size = 8\n",
    "epoch = 10\n",
    "N = len(X_train)\n",
    "optimizer = Sgd(lr=0.001)\n",
    "\n",
    "for i in range(epoch):\n",
    "    perm = np.random.permutation(N)\n",
    "    loss = 0\n",
    "    for j in range(0, N // batch_size):\n",
    "        train_batch = X_train[perm[j*batch_size : (j+1)*batch_size]]\n",
    "        response_batch = y_train[perm[j*batch_size : (j+1)*batch_size]]\n",
    "\n",
    "        with model.train():\n",
    "            l = rm.mean_squared_error(model(train_batch), response_batch)\n",
    "        grad = l.grad()\n",
    "        grad.update(optimizer)\n",
    "        loss += l.as_ndarray()\n",
    "    train_loss = loss / (N // batch_size)\n",
    "\n",
    "    test_loss = rm.mean_squared_error(model(X_test), y_test).as_ndarray()\n",
    "    print(\"epoch:{:03d}, train_loss:{:.4f}, test_loss:{:.4f}\".format(i, float(train_loss), float(test_loss)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
